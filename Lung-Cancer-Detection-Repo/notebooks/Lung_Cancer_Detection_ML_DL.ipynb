{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Lung Cancer Detection \u2014 ML + Deep Learning\n\nThis notebook demonstrates a combined classical ML and deep learning approach for tabular lung-cancer data. It is written to be easy to run in local Jupyter or Colab."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# Standard imports and settings\nimport os, warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nprint(\"Notebook ready \u2014 working directory:\", os.getcwd())\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Load dataset\ndata_path = Path(\"../data/dataset_med.csv\") if Path(\"../data/dataset_med.csv\").exists() else Path(\"data/dataset_med.csv\")\nprint(\"Loading from:\", data_path)\ndf = pd.read_csv(data_path)\nprint(\"Shape:\", df.shape)\ndf.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Quick EDA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# Basic EDA\ndisplay(df.describe(include='all').T)\nprint('\\nMissing values per column:')\nprint(df.isnull().sum())\n\n# If dataset is small, show value counts of target (if present)\nif 'target' in df.columns:\n    print('\\nTarget distribution:')\n    print(df['target'].value_counts())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Preprocessing\n- Handle missing values\n- Encode categorical features (if any)\n- Scale numerical features\n- Split train/test"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# Auto-detect target column: common names\npossible_targets = ['target','label','diagnosis','Outcome','class']\ntarget_col = next((c for c in df.columns if c.lower() in [p.lower() for p in possible_targets]), None)\nif target_col is None:\n    # pick the last column as target if detection fails\n    target_col = df.columns[-1]\n\nprint(\"Using target column:\", target_col)\nX = df.drop(columns=[target_col])\ny = df[target_col]\n\n# Simple imputation for numeric and categorical\nnumeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\ncat_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()\nprint(\"Numeric cols:\", numeric_cols)\nprint(\"Categorical cols:\", cat_cols)\n\nnumeric_transformer = Pipeline(steps=[('imputer', __import__('sklearn.impute').impute.SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\ncat_transformer = Pipeline(steps=[('imputer', __import__('sklearn.impute').impute.SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\npreprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_cols), ('cat', cat_transformer, cat_cols)])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y if len(np.unique(y))>1 else None)\n\nprint(\"Train/test split:\", X_train.shape, X_test.shape)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Classical ML models (Logistic Regression, Random Forest)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n\n# Logistic Regression pipeline\npipe_lr = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\npipe_lr.fit(X_train, y_train)\ny_pred_lr = pipe_lr.predict(X_test)\nprint(\"Logistic Regression\\n\", classification_report(y_test, y_pred_lr))\ntry:\n    y_prob_lr = pipe_lr.predict_proba(X_test)[:,1]\n    print(\"ROC AUC (LR):\", roc_auc_score(y_test, y_prob_lr))\nexcept Exception as e:\n    print(\"Could not compute predict_proba for LR:\", e)\n\n# Random Forest pipeline\npipe_rf = make_pipeline(preprocessor, RandomForestClassifier(n_estimators=100, random_state=42))\npipe_rf.fit(X_train, y_train)\ny_pred_rf = pipe_rf.predict(X_test)\nprint(\"Random Forest\\n\", classification_report(y_test, y_pred_rf))\ntry:\n    y_prob_rf = pipe_rf.predict_proba(X_test)[:,1]\n    print(\"ROC AUC (RF):\", roc_auc_score(y_test, y_prob_rf))\nexcept Exception as e:\n    print(\"Could not compute predict_proba for RF:\", e)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Deep Learning model (Keras MLP for tabular data)\nIf you have images, replace this section with a CNN and image generators."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\n# Deep learning using TensorFlow / Keras\ntry:\n    import tensorflow as tf\n    from tensorflow import keras\n    from tensorflow.keras import layers\n    print(\"TensorFlow version:\", tf.__version__)\n    use_tf = True\nexcept Exception as e:\n    print(\"TensorFlow not available in this environment. The code remains, but won't run until TF is installed.\", e)\n    use_tf = False\n\nif use_tf:\n    # Prepare numeric numpy arrays (after preprocessing)\n    X_train_proc = preprocessor.fit_transform(X_train)\n    X_test_proc = preprocessor.transform(X_test)\n\n    # If categorical one-hot expansion produced sparse matrix, convert to array\n    import numpy as np\n    if hasattr(X_train_proc, \"toarray\"):\n        X_train_proc = X_train_proc.toarray()\n        X_test_proc = X_test_proc.toarray()\n\n    input_dim = X_train_proc.shape[1]\n    model = keras.Sequential([\n        layers.Input(shape=(input_dim,)),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(64, activation='relu'),\n        layers.Dropout(0.2),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    history = model.fit(X_train_proc, y_train, validation_split=0.15, epochs=30, batch_size=32, verbose=1)\n\n    # Evaluate\n    loss, acc = model.evaluate(X_test_proc, y_test, verbose=0)\n    print(\"DL model accuracy:\", acc)\n\n    # Predictions and reports\n    y_prob_dl = model.predict(X_test_proc).ravel()\n    y_pred_dl = (y_prob_dl > 0.5).astype(int)\n    from sklearn.metrics import classification_report, roc_auc_score\n    print(classification_report(y_test, y_pred_dl))\n    try:\n        print(\"ROC AUC (DL):\", roc_auc_score(y_test, y_prob_dl))\n    except:\n        pass\nelse:\n    print(\"Install TensorFlow to run the deep learning section. You can run this notebook on Google Colab where TF is preinstalled.\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Visualizations (Confusion Matrix, ROC)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nfrom sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\nimport matplotlib.pyplot as plt\n\n# Confusion matrix for best classical model (choose RF here)\ntry:\n    ConfusionMatrixDisplay.from_estimator(pipe_rf, X_test, y_test)\n    plt.title('Random Forest Confusion Matrix')\n    plt.show()\nexcept Exception as e:\n    print('Could not plot confusion matrix:', e)\n\n# ROC for classical models if probabilities exist\ntry:\n    import matplotlib.pyplot as plt\n    plt.figure()\n    if 'y_prob_lr' in globals():\n        RocCurveDisplay.from_predictions(y_test, y_prob_lr, name='Logistic Regression')\n    if 'y_prob_rf' in globals():\n        RocCurveDisplay.from_predictions(y_test, y_prob_rf, name='Random Forest')\n    plt.legend()\n    plt.show()\nexcept Exception as e:\n    print('Could not plot ROC:', e)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Save models (optional)\nWe save classical models using joblib and DL model using Keras `model.save()`"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\nimport joblib, os\nos.makedirs('models', exist_ok=True)\njoblib.dump(pipe_rf, 'models/random_forest_pipeline.joblib')\njoblib.dump(pipe_lr, 'models/logistic_regression_pipeline.joblib')\nprint('Saved classical model pipelines to models/')\n\nif use_tf and 'model' in globals():\n    model.save('models/dl_model.h5')\n    print('Saved DL model to models/dl_model.h5')\n"
    },
   
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
